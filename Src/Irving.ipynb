{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IT1244 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re as re\n",
    "import heapq as heapq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MultiLabelBinarizer, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Bert Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Bert Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load tokenizer and model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Encode sentences\n",
    "sentence1 = \"This is an example sentence with change negative.\"\n",
    "inputs1 = tokenizer(sentence1, return_tensors=\"pt\")\n",
    "\n",
    "sentence2 = \"This is an example sentence with change upset.\"\n",
    "inputs2 = tokenizer(sentence2, return_tensors=\"pt\")\n",
    "\n",
    "sentence3 = \"This is an example sentence with change happy.\"\n",
    "inputs3 = tokenizer(sentence3, return_tensors=\"pt\")\n",
    "\n",
    "# Get embeddings\n",
    "with torch.no_grad():\n",
    "    outputs1 = model(**inputs1)\n",
    "    outputs2 = model(**inputs2)\n",
    "    outputs3 = model(**inputs3)\n",
    "\n",
    "# Extract [CLS] token embedding (sentence-level representation)\n",
    "Vector_X = outputs1.last_hidden_state[:, 0, :]\n",
    "Vector_Y = outputs2.last_hidden_state[:, 0, :]\n",
    "Vector_Z = outputs3.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878990054130554"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(cosine_similarity(Vector_X, Vector_Y)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982489287853241"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(cosine_similarity(Vector_X, Vector_Z)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "    return output.last_hidden_state[:, 0, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the closer concepts are have higher cosine similiarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  sentiment_confidence  \\\n",
       "0           neutral                1.0000   \n",
       "1          positive                0.3486   \n",
       "2           neutral                0.6837   \n",
       "3          negative                1.0000   \n",
       "4          negative                1.0000   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"../Data/Raw/Tweets.csv\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14639, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@VirginAmerica plus you've added commercials to the experience... tacky.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def at_filter(text):\n",
    "    return re.sub(r\"@\\w+\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_filter(text):\n",
    "    return re.sub(r'[^A-Za-z ]', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: at_filter(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: alpha_filter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>What  said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>plus youve added commercials to the experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>I didnt today Must mean I need to take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>its really aggressive to blast obnoxious ente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>and its a really big bad thing about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>thank you we got on a different flight to Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>leaving over  minutes Late Flight No warnings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Please bring American Airlines to BlackBerry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>you have my money you change my flight and do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>we have  ppl so we need  know how many seats ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14639 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment  sentiment_confidence  \\\n",
       "0               neutral                1.0000   \n",
       "1              positive                0.3486   \n",
       "2               neutral                0.6837   \n",
       "3              negative                1.0000   \n",
       "4              negative                1.0000   \n",
       "...                 ...                   ...   \n",
       "14634          positive                0.3487   \n",
       "14635          negative                1.0000   \n",
       "14636           neutral                1.0000   \n",
       "14637          negative                1.0000   \n",
       "14638           neutral                0.6771   \n",
       "\n",
       "                                                    text  \n",
       "0                                             What  said  \n",
       "1       plus youve added commercials to the experienc...  \n",
       "2       I didnt today Must mean I need to take anothe...  \n",
       "3       its really aggressive to blast obnoxious ente...  \n",
       "4                and its a really big bad thing about it  \n",
       "...                                                  ...  \n",
       "14634   thank you we got on a different flight to Chi...  \n",
       "14635   leaving over  minutes Late Flight No warnings...  \n",
       "14636       Please bring American Airlines to BlackBerry  \n",
       "14637   you have my money you change my flight and do...  \n",
       "14638   we have  ppl so we need  know how many seats ...  \n",
       "\n",
       "[14639 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets[\"text\"], tweets[\"airline_sentiment\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv(\"../Data/Cleaned/CleanTweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(map(lambda x: len(x), tweets[\"text\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = tweets[\"text\"].apply(lambda x: bert_encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(list(map(lambda x: x[0], sentence_vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14639, 768)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnKmeans(X, k, m):\n",
    "    '''\n",
    "    X: numpy array, shape = [N, D]\n",
    "    k: int value\n",
    "    m: int value\n",
    "    RETURN\n",
    "        position: numpy array, shape = [N]\n",
    "        centers: numpy array, shape = [k, D]\n",
    "    '''\n",
    "    position, centers = None, None\n",
    "    ## start your code here\n",
    "    kmeans = KMeans(n_clusters=k,n_init=1, max_iter=m).fit(X)\n",
    "    position, centers = kmeans.predict(X), kmeans.cluster_centers_\n",
    "    ## end\n",
    "    return position, centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "position, centers = sklearnKmeans(data, 3, 10000)\n",
    "labels = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([12427]), array([652]), array([], dtype=int64)]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_indexes = [np.where(data == center)[0] for center in centers]\n",
    "centroid_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([12427]), array([652])]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_indexes = list(filter(lambda x: x.size > 0, centroid_indexes))\n",
    "centroid_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelling the centroids to test accuracy\n",
    "possible_labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "possible_clusters = [0, 1, 2]\n",
    "\n",
    "# Cluster 1\n",
    "sentiment_label = tweets[\"airline_sentiment\"][centroid_indexes[0]].to_string().split()[1]\n",
    "cluster = position[centroid_indexes[0]][0]\n",
    "labels[int(cluster)] = sentiment_label\n",
    "possible_labels.remove(sentiment_label)\n",
    "possible_clusters.remove(cluster)\n",
    "\n",
    "# Cluster 2\n",
    "sentiment_label = tweets[\"airline_sentiment\"][centroid_indexes[1]].to_string().split()[1]\n",
    "cluster = position[centroid_indexes[1]][0]\n",
    "labels[int(cluster)] = sentiment_label\n",
    "possible_labels.remove(sentiment_label)\n",
    "possible_clusters.remove(cluster)\n",
    "\n",
    "# Cluster 3\n",
    "labels[possible_clusters[0]] = possible_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'positive', 2: 'negative', 0: 'neutral'}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentiments = list(map(lambda x: labels[x], position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 40.08%\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(tweets[\"airline_sentiment\"] ==  predicted_sentiments)\n",
    "print(f\"accuracy is {np.round(accuracy*100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
